import { GoogleGenAI } from '@google/genai';
import dotenv from 'dotenv';
dotenv.config();

const genAi = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY || '',
});

// falback
const ABUSE_MESSAGES: Record<number, string[]> = {
  0: [
    'Hey! Just a friendly reminder to keep your streak going today ðŸ”¥',
    "Don't forget your streak! You've got this ðŸ’ª",
  ],
  1: [
    "Your streak is about to break... don't be that person ðŸ˜¤",
    'Streak alert! Are you seriously going to let this die? ðŸ« ',
  ],
  2: [
    "YOUR STREAK IS DYING AND IT'S YOUR FAULT ðŸ’€",
    'Imagine losing a streak because you were too lazy to post. Could not be me. Oh wait, it IS you ðŸ¤¡',
  ],
  3: [
    "You absolute walnut. Your streak is about to die and you're doing NOTHING about it ðŸ¥œðŸ’€",
    'Breaking your streak? In THIS economy? Pathetic. ðŸ“‰ðŸ¤®',
  ],
};

export async function generateAbuseMessage(
  abuseLevel: number,
  userInfo: { currentCount: number; streakName: string },
  messageType: 'dm' | 'post'
): Promise<string> {
  const prompt = `
You are generating a comedic roast message for a streak-based app.

Context:
- The user has a ${userInfo.currentCount}-day streak.
- The streak is called "${userInfo.streakName}".
- Abuse level: ${abuseLevel} (1=light tease, 2=strong roast, 3=extreme chaotic roast).
- Message type: ${messageType === 'dm' ? 'Private reminder (DM)' : 'Public shame post'}.

Tone rules by abuse level:
1 â†’ Playful teasing. Light sarcasm. No profanity.
2 â†’ Aggressive roast energy. Dramatic exaggeration. Mild profanity allowed. No real cruelty.
3 â†’ Unhinged, chaotic, over-the-top roast. Strong profanity allowed. Absurd exaggeration.

Message type rules:
- If DM: It can encourage them to keep going (especially levels 0â€“2).
- If Post: It should feel like public humiliation humor. No encouragement required. Just funny roast energy.


Write only the message text. Keep it under 120 words.
`;

  try {
    const response = await genAi.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: {
        maxOutputTokens: 300, // roughly 120 words
        temperature: 0.9,
      },
    });

    if (!response.text) {
      // fallback to default messages if ai generation fails for any reason
      const messages = ABUSE_MESSAGES[abuseLevel] || ABUSE_MESSAGES[0];
      return messages[Math.floor(Math.random() * messages.length)];
    }

    return response.text?.trim();
  } catch (error) {
    const messages = ABUSE_MESSAGES[abuseLevel] || ABUSE_MESSAGES[0];
    return messages[Math.floor(Math.random() * messages.length)];
  }
}
